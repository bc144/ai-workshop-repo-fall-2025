{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711f0c84",
   "metadata": {},
   "source": [
    "# ETL\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- xgboost\n",
    "- pandas\n",
    "- seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48a7ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Track                    Album Name          Artist  \\\n",
      "0         MILLION DOLLAR BABY  Million Dollar Baby - Single   Tommy Richman   \n",
      "1                 Not Like Us                   Not Like Us  Kendrick Lamar   \n",
      "2  i like the way you kiss me    I like the way you kiss me         Artemas   \n",
      "3                     Flowers              Flowers - Single     Miley Cyrus   \n",
      "4                     Houdini                       Houdini          Eminem   \n",
      "\n",
      "  Release Date          ISRC All Time Rank  Track Score Spotify Streams  \\\n",
      "0    4/26/2024  QM24S2402528             1        725.4     390,470,936   \n",
      "1     5/4/2024  USUG12400910             2        545.9     323,703,884   \n",
      "2    3/19/2024  QZJ842400387             3        538.4     601,309,283   \n",
      "3    1/12/2023  USSM12209777             4        444.9   2,031,280,633   \n",
      "4    5/31/2024  USUG12403398             5        423.3     107,034,922   \n",
      "\n",
      "  Spotify Playlist Count Spotify Playlist Reach  ...  SiriusXM Spins  \\\n",
      "0                 30,716            196,631,588  ...             684   \n",
      "1                 28,113            174,597,137  ...               3   \n",
      "2                 54,331            211,607,669  ...             536   \n",
      "3                269,802            136,569,078  ...           2,182   \n",
      "4                  7,223            151,469,874  ...               1   \n",
      "\n",
      "  Deezer Playlist Count Deezer Playlist Reach Amazon Playlist Count  \\\n",
      "0                  62.0            17,598,718                 114.0   \n",
      "1                  67.0            10,422,430                 111.0   \n",
      "2                 136.0            36,321,847                 172.0   \n",
      "3                 264.0            24,684,248                 210.0   \n",
      "4                  82.0            17,660,624                 105.0   \n",
      "\n",
      "  Pandora Streams Pandora Track Stations Soundcloud Streams  Shazam Counts  \\\n",
      "0      18,004,655                 22,931          4,818,457      2,669,262   \n",
      "1       7,780,028                 28,444          6,623,075      1,118,279   \n",
      "2       5,022,621                  5,639          7,208,651      5,285,340   \n",
      "3     190,260,277                203,384                NaN     11,822,942   \n",
      "4       4,493,884                  7,006            207,179        457,017   \n",
      "\n",
      "  TIDAL Popularity Explicit Track  \n",
      "0              NaN              0  \n",
      "1              NaN              1  \n",
      "2              NaN              0  \n",
      "3              NaN              0  \n",
      "4              NaN              1  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "file_id = \"1hUvKweiaYPyRxT5knbO1x9qmNmIFZRSW\"\n",
    "download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "\n",
    "response = requests.get(download_url)\n",
    "\n",
    "\n",
    "df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e30295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "368b3bd8",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "- Dataset dimensions\n",
    "- Column names and data types\n",
    "- Missing values analysis\n",
    "- Describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465c70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- DATASET OVERVIEW -\n",
      "Dataset shape: (4600, 29)\n",
      "Number of rows: 4,600\n",
      "Number of columns: 29\n",
      "\n",
      "\n",
      "Column names:\n",
      "- COLUMN INFORMATION -\n",
      " 1. Track\n",
      " 2. Album Name\n",
      " 3. Artist\n",
      " 4. Release Date\n",
      " 5. ISRC\n",
      " 6. All Time Rank\n",
      " 7. Track Score\n",
      " 8. Spotify Streams\n",
      " 9. Spotify Playlist Count\n",
      "10. Spotify Playlist Reach\n",
      "11. Spotify Popularity\n",
      "12. YouTube Views\n",
      "13. YouTube Likes\n",
      "14. TikTok Posts\n",
      "15. TikTok Likes\n",
      "16. TikTok Views\n",
      "17. YouTube Playlist Reach\n",
      "18. Apple Music Playlist Count\n",
      "19. AirPlay Spins\n",
      "20. SiriusXM Spins\n",
      "21. Deezer Playlist Count\n",
      "22. Deezer Playlist Reach\n",
      "23. Amazon Playlist Count\n",
      "24. Pandora Streams\n",
      "25. Pandora Track Stations\n",
      "26. Soundcloud Streams\n",
      "27. Shazam Counts\n",
      "28. TIDAL Popularity\n",
      "29. Explicit Track\n",
      "\n",
      "\n",
      "- DATA TYPES -\n",
      "Track                          object\n",
      "Album Name                     object\n",
      "Artist                         object\n",
      "Release Date                   object\n",
      "ISRC                           object\n",
      "All Time Rank                  object\n",
      "Track Score                   float64\n",
      "Spotify Streams                object\n",
      "Spotify Playlist Count         object\n",
      "Spotify Playlist Reach         object\n",
      "Spotify Popularity            float64\n",
      "YouTube Views                  object\n",
      "YouTube Likes                  object\n",
      "TikTok Posts                   object\n",
      "TikTok Likes                   object\n",
      "TikTok Views                   object\n",
      "YouTube Playlist Reach         object\n",
      "Apple Music Playlist Count    float64\n",
      "AirPlay Spins                  object\n",
      "SiriusXM Spins                 object\n",
      "Deezer Playlist Count         float64\n",
      "Deezer Playlist Reach          object\n",
      "Amazon Playlist Count         float64\n",
      "Pandora Streams                object\n",
      "Pandora Track Stations         object\n",
      "Soundcloud Streams             object\n",
      "Shazam Counts                  object\n",
      "TIDAL Popularity              float64\n",
      "Explicit Track                  int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "- MISSING VALUES  -\n",
      "Columns with missing values:\n",
      "                            Missing Count  Missing Percentage\n",
      "TIDAL Popularity                     4600              100.00\n",
      "Soundcloud Streams                   3333               72.46\n",
      "SiriusXM Spins                       2123               46.15\n",
      "Pandora Track Stations               1268               27.57\n",
      "TikTok Posts                         1173               25.50\n",
      "Pandora Streams                      1106               24.04\n",
      "Amazon Playlist Count                1055               22.93\n",
      "YouTube Playlist Reach               1009               21.93\n",
      "TikTok Views                          981               21.33\n",
      "TikTok Likes                          980               21.30\n",
      "Deezer Playlist Reach                 928               20.17\n",
      "Deezer Playlist Count                 921               20.02\n",
      "Spotify Popularity                    804               17.48\n",
      "Shazam Counts                         577               12.54\n",
      "Apple Music Playlist Count            561               12.20\n",
      "AirPlay Spins                         498               10.83\n",
      "YouTube Likes                         315                6.85\n",
      "YouTube Views                         308                6.70\n",
      "Spotify Streams                       113                2.46\n",
      "Spotify Playlist Reach                 72                1.57\n",
      "Spotify Playlist Count                 70                1.52\n",
      "Artist                                  5                0.11\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Score</th>\n",
       "      <th>Spotify Popularity</th>\n",
       "      <th>Apple Music Playlist Count</th>\n",
       "      <th>Deezer Playlist Count</th>\n",
       "      <th>Amazon Playlist Count</th>\n",
       "      <th>TIDAL Popularity</th>\n",
       "      <th>Explicit Track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>3796.000000</td>\n",
       "      <td>4039.00000</td>\n",
       "      <td>3679.000000</td>\n",
       "      <td>3545.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.844043</td>\n",
       "      <td>63.501581</td>\n",
       "      <td>54.60312</td>\n",
       "      <td>32.310954</td>\n",
       "      <td>25.348942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.543766</td>\n",
       "      <td>16.186438</td>\n",
       "      <td>71.61227</td>\n",
       "      <td>54.274538</td>\n",
       "      <td>25.989826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.300000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.900000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.425000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>725.400000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>859.00000</td>\n",
       "      <td>632.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Track Score  Spotify Popularity  Apple Music Playlist Count  \\\n",
       "count  4600.000000         3796.000000                  4039.00000   \n",
       "mean     41.844043           63.501581                    54.60312   \n",
       "std      38.543766           16.186438                    71.61227   \n",
       "min      19.400000            1.000000                     1.00000   \n",
       "25%      23.300000           61.000000                    10.00000   \n",
       "50%      29.900000           67.000000                    28.00000   \n",
       "75%      44.425000           73.000000                    70.00000   \n",
       "max     725.400000           96.000000                   859.00000   \n",
       "\n",
       "       Deezer Playlist Count  Amazon Playlist Count  TIDAL Popularity  \\\n",
       "count            3679.000000            3545.000000               0.0   \n",
       "mean               32.310954              25.348942               NaN   \n",
       "std                54.274538              25.989826               NaN   \n",
       "min                 1.000000               1.000000               NaN   \n",
       "25%                 5.000000               8.000000               NaN   \n",
       "50%                15.000000              17.000000               NaN   \n",
       "75%                37.000000              34.000000               NaN   \n",
       "max               632.000000             210.000000               NaN   \n",
       "\n",
       "       Explicit Track  \n",
       "count     4600.000000  \n",
       "mean         0.358913  \n",
       "std          0.479734  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Dataset Structure Overview\n",
    "print(\"- DATASET OVERVIEW -\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]:,}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Column Information\n",
    "print(\"Column names:\")\n",
    "print(\"- COLUMN INFORMATION -\")\n",
    "for i, col in enumerate(df.columns, 1): \n",
    "    print(f\"{i:2d}. {col}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Data Types Analysis\n",
    "print(\"- DATA TYPES -\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Missing Values \n",
    "print(\"- MISSING VALUES  -\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "# Only show columns with missing values\n",
    "columns_with_missing = missing_summary[missing_summary['Missing Count'] > 0]\n",
    "if len(columns_with_missing) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(columns_with_missing.sort_values('Missing Count', ascending=False))\n",
    "else:\n",
    "    print(\"✓ No missing values found in the dataset!\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 5. Summary of data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98574e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED DATA TYPE ANALYSIS ===\n",
      "Numeric columns (7):\n",
      "  • Track Score\n",
      "  • Spotify Popularity\n",
      "  • Apple Music Playlist Count\n",
      "  • Deezer Playlist Count\n",
      "  • Amazon Playlist Count\n",
      "  • TIDAL Popularity\n",
      "  • Explicit Track\n",
      "\n",
      "Text/Object columns (22):\n",
      "  • Track\n",
      "  • Album Name\n",
      "  • Artist\n",
      "  • Release Date\n",
      "  • ISRC\n",
      "  • All Time Rank\n",
      "  • Spotify Streams\n",
      "  • Spotify Playlist Count\n",
      "  • Spotify Playlist Reach\n",
      "  • YouTube Views\n",
      "  • YouTube Likes\n",
      "  • TikTok Posts\n",
      "  • TikTok Likes\n",
      "  • TikTok Views\n",
      "  • YouTube Playlist Reach\n",
      "  • AirPlay Spins\n",
      "  • SiriusXM Spins\n",
      "  • Deezer Playlist Reach\n",
      "  • Pandora Streams\n",
      "  • Pandora Track Stations\n",
      "  • Soundcloud Streams\n",
      "  • Shazam Counts\n",
      "\n",
      "=== UNIQUE VALUES ANALYSIS ===\n",
      "Number of unique values per column:\n",
      "ISRC: 4,598 unique values (100.0%)\n",
      "All Time Rank: 4,577 unique values (99.5%)\n",
      "Spotify Playlist Reach: 4,478 unique values (97.3%)\n",
      "Spotify Streams: 4,425 unique values (96.2%)\n",
      "Track: 4,370 unique values (95.0%)\n",
      "YouTube Views: 4,290 unique values (93.3%)\n",
      "YouTube Likes: 4,283 unique values (93.1%)\n",
      "Spotify Playlist Count: 4,207 unique values (91.5%)\n",
      "Album Name: 4,005 unique values (87.1%)\n",
      "Shazam Counts: 4,002 unique values (87.0%)\n",
      "TikTok Views: 3,616 unique values (78.6%)\n",
      "TikTok Likes: 3,615 unique values (78.6%)\n",
      "Deezer Playlist Reach: 3,558 unique values (77.3%)\n",
      "Pandora Streams: 3,491 unique values (75.9%)\n",
      "YouTube Playlist Reach: 3,458 unique values (75.2%)\n",
      "TikTok Posts: 3,318 unique values (72.1%)\n",
      "AirPlay Spins: 3,267 unique values (71.0%)\n",
      "Pandora Track Stations: 2,975 unique values (64.7%)\n",
      "Artist: 1,999 unique values (43.5%)\n",
      "Release Date: 1,562 unique values (34.0%)\n",
      "Soundcloud Streams: 1,265 unique values (27.5%)\n",
      "Track Score: 862 unique values (18.7%)\n",
      "SiriusXM Spins: 689 unique values (15.0%)\n",
      "Apple Music Playlist Count: 322 unique values (7.0%)\n",
      "Deezer Playlist Count: 233 unique values (5.1%)\n",
      "Amazon Playlist Count: 147 unique values (3.2%)\n",
      "Spotify Popularity: 94 unique values (2.0%)\n",
      "Explicit Track: 2 unique values (0.0%)\n",
      "TIDAL Popularity: 0 unique values (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Additional Data Type Analysis\n",
    "print(\"=== DETAILED DATA TYPE ANALYSIS ===\")\n",
    "\n",
    "# Categorize columns by data type\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "object_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "date_time_cols = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "\n",
    "\n",
    "print(f\"Numeric columns ({len(numeric_cols)}):\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "print(f\"\\nText/Object columns ({len(object_cols)}):\")\n",
    "for col in object_cols:\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== UNIQUE VALUES ANALYSIS ===\")\n",
    "print(\"Number of unique values per column:\")\n",
    "unique_counts = df.nunique().sort_values(ascending=False)\n",
    "for col, count in unique_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{col}: {count:,} unique values ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aede2c5",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "\n",
    "1. **Data Cleaning**: Handle missing values, duplicates, and inconsistencies\n",
    "2. **Encoding**: Convert categorical variables to numerical format\n",
    "3. **Normalization/Standardization**: Apply scaling where needed\n",
    "4. **Feature Selection**: Choose appropriate predictor variables\n",
    "5. **Feature Engineering**: Create new meaningful features\n",
    "6. **Additional Transformations**: Apply domain-specific transformations\n",
    "\n",
    "Things to note\n",
    "1. We can eithere delete all rows that are missing or replace the value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47aa3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Copy for transformatuon\n",
    "df_original = df.copy() \n",
    "df_transformed = df.copy()  # Working copy for transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c787239",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "\n",
    "We will Drop all TIDAL Popularity rows since they are all null, not worth keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7108f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_transformed.drop(columns=['TIDAL Popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750764a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 4035\n",
      "Percentage of rows with missing values: 87.72%\n"
     ]
    }
   ],
   "source": [
    "#How many rows have missing values?\n",
    "missing_counter = df_transformed.isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with missing values: {missing_counter}\")\n",
    "\n",
    "percentage = (missing_counter / len(df_transformed)) * 100\n",
    "print(f\"Percentage of rows with missing values: {percentage:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600a587a",
   "metadata": {},
   "source": [
    "Even after dropping TIDAL Popularity still most rows are missing at least one field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f149876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Artist                           5\n",
      "Spotify Streams                113\n",
      "Spotify Playlist Count          70\n",
      "Spotify Playlist Reach          72\n",
      "Spotify Popularity             804\n",
      "YouTube Views                  308\n",
      "YouTube Likes                  315\n",
      "TikTok Posts                  1173\n",
      "TikTok Likes                   980\n",
      "TikTok Views                   981\n",
      "YouTube Playlist Reach        1009\n",
      "Apple Music Playlist Count     561\n",
      "AirPlay Spins                  498\n",
      "SiriusXM Spins                2123\n",
      "Deezer Playlist Count          921\n",
      "Deezer Playlist Reach          928\n",
      "Amazon Playlist Count         1055\n",
      "Pandora Streams               1106\n",
      "Pandora Track Stations        1268\n",
      "Soundcloud Streams            3333\n",
      "Shazam Counts                  577\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_cols = df_transformed.isnull().sum()\n",
    "missing_cols = missing_cols[missing_cols > 0]\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ea311",
   "metadata": {},
   "source": [
    "Since most entries vary on what value is missing removing more columns would not be ideal, we will first convert columns that have a wrong type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c276b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NUMERIC COLUMN CLEANING ===\n",
      "✓ Cleaned 'Spotify Streams' - filled missing values with median: 239,850,720\n",
      "✓ Cleaned 'Spotify Playlist Count' - filled missing values with median: 32,312\n",
      "✓ Cleaned 'Spotify Playlist Reach' - filled missing values with median: 13,259,481\n",
      "✓ Cleaned 'YouTube Views' - filled missing values with median: 148,269,610\n",
      "✓ Cleaned 'YouTube Likes' - filled missing values with median: 1,257,935\n",
      "✓ Cleaned 'TikTok Posts' - filled missing values with median: 182,200\n",
      "✓ Cleaned 'TikTok Likes' - filled missing values with median: 26,534,406\n",
      "✓ Cleaned 'TikTok Views' - filled missing values with median: 265,917,250\n",
      "✓ Cleaned 'YouTube Playlist Reach' - filled missing values with median: 98,142,716\n",
      "✓ Cleaned 'AirPlay Spins' - filled missing values with median: 5,954\n",
      "✓ Cleaned 'SiriusXM Spins' - filled missing values with median: 86\n",
      "✓ Cleaned 'Deezer Playlist Reach' - filled missing values with median: 237,120\n",
      "✓ Cleaned 'Pandora Streams' - filled missing values with median: 12,735,768\n",
      "✓ Cleaned 'Pandora Track Stations' - filled missing values with median: 7,832\n",
      "✓ Cleaned 'Soundcloud Streams' - filled missing values with median: 3,224,599\n",
      "✓ Cleaned 'Shazam Counts' - filled missing values with median: 854,584\n",
      "\n",
      "Total columns processed: 16\n"
     ]
    }
   ],
   "source": [
    "# List of columns to convert to int\n",
    "int_columns = [\n",
    "    \"Spotify Streams\",\n",
    "    \"Spotify Playlist Count\",\n",
    "    \"Spotify Playlist Reach\",\n",
    "    \"YouTube Views\",\n",
    "    \"YouTube Likes\",\n",
    "    \"TikTok Posts\",\n",
    "    \"TikTok Likes\",\n",
    "    \"TikTok Views\",\n",
    "    \"YouTube Playlist Reach\",\n",
    "    \"AirPlay Spins\",\n",
    "    \"SiriusXM Spins\",\n",
    "    \"Deezer Playlist Reach\",\n",
    "    \"Pandora Streams\",\n",
    "    \"Pandora Track Stations\",\n",
    "    \"Soundcloud Streams\",\n",
    "    \"Shazam Counts\"\n",
    "]\n",
    "\n",
    "# Function to clean \n",
    "def clean_numeric_column(series):\n",
    "    \"\"\"\n",
    "    Clean numeric column by removing commas, converting to numeric, \n",
    "    and filling missing values with median\n",
    "    \"\"\"\n",
    "    # Remove commas and convert to string first\n",
    "    cleaned = series.astype(str).str.replace(',', '', regex=False)\n",
    "    # Convert to numeric, coerce errors to NaN\n",
    "    numeric = pd.to_numeric(cleaned, errors='coerce')\n",
    "    # Calculate median before filling NaN\n",
    "    median_val = numeric.median()\n",
    "    # Fill NaN with median and convert to int\n",
    "    return numeric.fillna(median_val).astype(int), median_val\n",
    "\n",
    "# Apply cleaning to each column and track median values used\n",
    "print(\"=== NUMERIC COLUMN CLEANING ===\")\n",
    "median_values_used = {}\n",
    "\n",
    "for col in int_columns:\n",
    "    if col in df_transformed.columns:\n",
    "        df_transformed[col], median_used = clean_numeric_column(df_transformed[col])\n",
    "        median_values_used[col] = median_used\n",
    "        print(f\"✓ Cleaned '{col}' - filled missing values with median: {median_used:,.0f}\")\n",
    "\n",
    "print(f\"\\nTotal columns processed: {len(median_values_used)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32feb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Score</th>\n",
       "      <th>Spotify Streams</th>\n",
       "      <th>Spotify Playlist Count</th>\n",
       "      <th>Spotify Playlist Reach</th>\n",
       "      <th>Spotify Popularity</th>\n",
       "      <th>YouTube Views</th>\n",
       "      <th>YouTube Likes</th>\n",
       "      <th>TikTok Posts</th>\n",
       "      <th>TikTok Likes</th>\n",
       "      <th>TikTok Views</th>\n",
       "      <th>...</th>\n",
       "      <th>AirPlay Spins</th>\n",
       "      <th>SiriusXM Spins</th>\n",
       "      <th>Deezer Playlist Count</th>\n",
       "      <th>Deezer Playlist Reach</th>\n",
       "      <th>Amazon Playlist Count</th>\n",
       "      <th>Pandora Streams</th>\n",
       "      <th>Pandora Track Stations</th>\n",
       "      <th>Soundcloud Streams</th>\n",
       "      <th>Shazam Counts</th>\n",
       "      <th>Explicit Track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>3796.000000</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>3679.000000</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>3545.000000</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.844043</td>\n",
       "      <td>4.422891e+08</td>\n",
       "      <td>58978.760652</td>\n",
       "      <td>2.318893e+07</td>\n",
       "      <td>63.501581</td>\n",
       "      <td>3.857545e+08</td>\n",
       "      <td>2.815545e+06</td>\n",
       "      <td>7.499702e+05</td>\n",
       "      <td>9.429377e+07</td>\n",
       "      <td>9.702380e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>4.981422e+04</td>\n",
       "      <td>178.265217</td>\n",
       "      <td>32.310954</td>\n",
       "      <td>1.081535e+06</td>\n",
       "      <td>25.348942</td>\n",
       "      <td>6.813206e+07</td>\n",
       "      <td>6.581240e+04</td>\n",
       "      <td>6.426079e+06</td>\n",
       "      <td>2.319100e+06</td>\n",
       "      <td>0.358913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.543766</td>\n",
       "      <td>5.327575e+08</td>\n",
       "      <td>70665.805879</td>\n",
       "      <td>2.948048e+07</td>\n",
       "      <td>16.186438</td>\n",
       "      <td>6.809681e+08</td>\n",
       "      <td>4.453607e+06</td>\n",
       "      <td>2.133783e+06</td>\n",
       "      <td>4.890001e+08</td>\n",
       "      <td>5.229587e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217568e+05</td>\n",
       "      <td>415.902340</td>\n",
       "      <td>54.274538</td>\n",
       "      <td>3.204872e+06</td>\n",
       "      <td>25.989826</td>\n",
       "      <td>1.495898e+08</td>\n",
       "      <td>2.248633e+05</td>\n",
       "      <td>1.764078e+07</td>\n",
       "      <td>5.674452e+06</td>\n",
       "      <td>0.479734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.400000</td>\n",
       "      <td>1.071000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.130000e+02</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.300000</td>\n",
       "      <td>7.317922e+07</td>\n",
       "      <td>7017.750000</td>\n",
       "      <td>4.906956e+06</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>4.572019e+07</td>\n",
       "      <td>4.483708e+05</td>\n",
       "      <td>6.747500e+04</td>\n",
       "      <td>9.401191e+06</td>\n",
       "      <td>9.367173e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.077500e+02</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.339675e+04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.602399e+06</td>\n",
       "      <td>2.732000e+03</td>\n",
       "      <td>3.224599e+06</td>\n",
       "      <td>2.884815e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.900000</td>\n",
       "      <td>2.398507e+08</td>\n",
       "      <td>32312.000000</td>\n",
       "      <td>1.325948e+07</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.482696e+08</td>\n",
       "      <td>1.257935e+06</td>\n",
       "      <td>1.822000e+05</td>\n",
       "      <td>2.653441e+07</td>\n",
       "      <td>2.659172e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.953000e+03</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.371200e+05</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.273577e+07</td>\n",
       "      <td>7.832000e+03</td>\n",
       "      <td>3.224599e+06</td>\n",
       "      <td>8.545840e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.425000</td>\n",
       "      <td>6.113563e+08</td>\n",
       "      <td>84908.250000</td>\n",
       "      <td>2.930526e+07</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.204637e+08</td>\n",
       "      <td>3.354867e+06</td>\n",
       "      <td>4.599832e+05</td>\n",
       "      <td>6.721851e+07</td>\n",
       "      <td>6.297186e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.646725e+04</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.076998e+05</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.669138e+07</td>\n",
       "      <td>2.363875e+04</td>\n",
       "      <td>3.224599e+06</td>\n",
       "      <td>2.242540e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>725.400000</td>\n",
       "      <td>4.281469e+09</td>\n",
       "      <td>590392.000000</td>\n",
       "      <td>2.623434e+08</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.632276e+10</td>\n",
       "      <td>6.231118e+07</td>\n",
       "      <td>4.290000e+07</td>\n",
       "      <td>2.347422e+10</td>\n",
       "      <td>2.332323e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.777811e+06</td>\n",
       "      <td>7098.000000</td>\n",
       "      <td>632.000000</td>\n",
       "      <td>4.819785e+07</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>1.463624e+09</td>\n",
       "      <td>3.780513e+06</td>\n",
       "      <td>3.198359e+08</td>\n",
       "      <td>2.197945e+08</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Track Score  Spotify Streams  Spotify Playlist Count  \\\n",
       "count  4600.000000     4.600000e+03             4600.000000   \n",
       "mean     41.844043     4.422891e+08            58978.760652   \n",
       "std      38.543766     5.327575e+08            70665.805879   \n",
       "min      19.400000     1.071000e+03                1.000000   \n",
       "25%      23.300000     7.317922e+07             7017.750000   \n",
       "50%      29.900000     2.398507e+08            32312.000000   \n",
       "75%      44.425000     6.113563e+08            84908.250000   \n",
       "max     725.400000     4.281469e+09           590392.000000   \n",
       "\n",
       "       Spotify Playlist Reach  Spotify Popularity  YouTube Views  \\\n",
       "count            4.600000e+03         3796.000000   4.600000e+03   \n",
       "mean             2.318893e+07           63.501581   3.857545e+08   \n",
       "std              2.948048e+07           16.186438   6.809681e+08   \n",
       "min              1.000000e+00            1.000000   9.130000e+02   \n",
       "25%              4.906956e+06           61.000000   4.572019e+07   \n",
       "50%              1.325948e+07           67.000000   1.482696e+08   \n",
       "75%              2.930526e+07           73.000000   4.204637e+08   \n",
       "max              2.623434e+08           96.000000   1.632276e+10   \n",
       "\n",
       "       YouTube Likes  TikTok Posts  TikTok Likes  TikTok Views  ...  \\\n",
       "count   4.600000e+03  4.600000e+03  4.600000e+03  4.600000e+03  ...   \n",
       "mean    2.815545e+06  7.499702e+05  9.429377e+07  9.702380e+08  ...   \n",
       "std     4.453607e+06  2.133783e+06  4.890001e+08  5.229587e+09  ...   \n",
       "min     2.500000e+01  1.000000e+00  3.000000e+00  1.900000e+01  ...   \n",
       "25%     4.483708e+05  6.747500e+04  9.401191e+06  9.367173e+07  ...   \n",
       "50%     1.257935e+06  1.822000e+05  2.653441e+07  2.659172e+08  ...   \n",
       "75%     3.354867e+06  4.599832e+05  6.721851e+07  6.297186e+08  ...   \n",
       "max     6.231118e+07  4.290000e+07  2.347422e+10  2.332323e+11  ...   \n",
       "\n",
       "       AirPlay Spins  SiriusXM Spins  Deezer Playlist Count  \\\n",
       "count   4.600000e+03     4600.000000            3679.000000   \n",
       "mean    4.981422e+04      178.265217              32.310954   \n",
       "std     1.217568e+05      415.902340              54.274538   \n",
       "min     1.000000e+00        1.000000               1.000000   \n",
       "25%     7.077500e+02       74.000000               5.000000   \n",
       "50%     5.953000e+03       86.000000              15.000000   \n",
       "75%     3.646725e+04      103.000000              37.000000   \n",
       "max     1.777811e+06     7098.000000             632.000000   \n",
       "\n",
       "       Deezer Playlist Reach  Amazon Playlist Count  Pandora Streams  \\\n",
       "count           4.600000e+03            3545.000000     4.600000e+03   \n",
       "mean            1.081535e+06              25.348942     6.813206e+07   \n",
       "std             3.204872e+06              25.989826     1.495898e+08   \n",
       "min             1.000000e+00               1.000000     2.000000e+00   \n",
       "25%             8.339675e+04               8.000000     2.602399e+06   \n",
       "50%             2.371200e+05              17.000000     1.273577e+07   \n",
       "75%             6.076998e+05              34.000000     4.669138e+07   \n",
       "max             4.819785e+07             210.000000     1.463624e+09   \n",
       "\n",
       "       Pandora Track Stations  Soundcloud Streams  Shazam Counts  \\\n",
       "count            4.600000e+03        4.600000e+03   4.600000e+03   \n",
       "mean             6.581240e+04        6.426079e+06   2.319100e+06   \n",
       "std              2.248633e+05        1.764078e+07   5.674452e+06   \n",
       "min              1.000000e+00        1.800000e+01   1.000000e+00   \n",
       "25%              2.732000e+03        3.224599e+06   2.884815e+05   \n",
       "50%              7.832000e+03        3.224599e+06   8.545840e+05   \n",
       "75%              2.363875e+04        3.224599e+06   2.242540e+06   \n",
       "max              3.780513e+06        3.198359e+08   2.197945e+08   \n",
       "\n",
       "       Explicit Track  \n",
       "count     4600.000000  \n",
       "mean         0.358913  \n",
       "std          0.479734  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f85f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert types\n",
    "\n",
    "# Convert Release Date column to datetime\n",
    "df_transformed[\"Release Date\"] = pd.to_datetime(df_transformed[\"Release Date\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "df_transformed[\"Explicit Track\"] = df_transformed[\"Explicit Track\"].astype(bool)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6380d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED DATA TYPE ANALYSIS ===\n",
      "Numeric columns (21):\n",
      "  • Track Score\n",
      "  • Spotify Streams\n",
      "  • Spotify Playlist Count\n",
      "  • Spotify Playlist Reach\n",
      "  • Spotify Popularity\n",
      "  • YouTube Views\n",
      "  • YouTube Likes\n",
      "  • TikTok Posts\n",
      "  • TikTok Likes\n",
      "  • TikTok Views\n",
      "  • YouTube Playlist Reach\n",
      "  • Apple Music Playlist Count\n",
      "  • AirPlay Spins\n",
      "  • SiriusXM Spins\n",
      "  • Deezer Playlist Count\n",
      "  • Deezer Playlist Reach\n",
      "  • Amazon Playlist Count\n",
      "  • Pandora Streams\n",
      "  • Pandora Track Stations\n",
      "  • Soundcloud Streams\n",
      "  • Shazam Counts\n",
      "\n",
      "Text/Object columns (5):\n",
      "  • Track\n",
      "  • Album Name\n",
      "  • Artist\n",
      "  • ISRC\n",
      "  • All Time Rank\n",
      "\n",
      "Datetime columns (1):\n",
      "  • Release Date\n",
      "\n",
      "Boolean columns (1):\n",
      "  • Explicit Track\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DETAILED DATA TYPE ANALYSIS ===\")\n",
    "\n",
    "# Categorize columns by data type\n",
    "numeric_cols = df_transformed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "object_cols = df_transformed.select_dtypes(include=['object']).columns.tolist()\n",
    "date_time_cols = df_transformed.select_dtypes(include=['datetime']).columns.tolist()\n",
    "boolean_cols = df_transformed.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric columns ({len(numeric_cols)}):\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "print(f\"\\nText/Object columns ({len(object_cols)}):\")\n",
    "for col in object_cols:\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "print(f\"\\nDatetime columns ({len(date_time_cols)}):\")\n",
    "for col in date_time_cols:\n",
    "    print(f\"  • {col}\")\n",
    "    \n",
    "print(f\"\\nBoolean columns ({len(boolean_cols)}):\")\n",
    "for col in boolean_cols:\n",
    "    print(f\"  • {col}\")\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648ab20",
   "metadata": {},
   "source": [
    "We have working data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791e709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REMAINING MISSING VALUES HANDLING ===\n",
      "Missing values before final cleaning:\n",
      "Artist                           5\n",
      "Spotify Popularity             804\n",
      "Apple Music Playlist Count     561\n",
      "Deezer Playlist Count          921\n",
      "Amazon Playlist Count         1055\n",
      "dtype: int64\n",
      "✓ Filled 5 missing values in 'Artist' with mode: 'Drake'\n",
      "✓ Filled 804 missing values in 'Spotify Popularity' with median: 67.0\n",
      "✓ Filled 561 missing values in 'Apple Music Playlist Count' with median: 28.0\n",
      "✓ Filled 921 missing values in 'Deezer Playlist Count' with median: 15.0\n",
      "✓ Filled 1055 missing values in 'Amazon Playlist Count' with median: 17.0\n",
      "\n",
      "Final missing values count: 0\n",
      "\n",
      "=== DUPLICATE HANDLING ===\n",
      "Duplicate rows found: 2\n",
      "Duplicate rows after removal: 0\n",
      "Rows removed: 2\n",
      "\n",
      "Dataset shape after cleaning: (4598, 28)\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Check for and handle remaining missing values\n",
    "print(\"=== REMAINING MISSING VALUES HANDLING ===\")\n",
    "missing_before = df_transformed.isnull().sum()\n",
    "missing_cols = missing_before[missing_before > 0]\n",
    "\n",
    "if len(missing_cols) > 0:\n",
    "    print(\"Missing values before final cleaning:\")\n",
    "    print(missing_cols)\n",
    "    \n",
    "    # Handle remaining missing values (non-numeric columns that weren't processed above)\n",
    "    for column in df_transformed.columns:\n",
    "        missing_count = df_transformed[column].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            if df_transformed[column].dtype in ['int64', 'float64']:\n",
    "                # For remaining numerical columns, use median\n",
    "                median_value = df_transformed[column].median()\n",
    "                df_transformed[column].fillna(median_value, inplace=True)\n",
    "                print(f\"✓ Filled {missing_count} missing values in '{column}' with median: {median_value}\")\n",
    "            elif df_transformed[column].dtype in ['datetime64[ns]', 'datetime']:\n",
    "                # Fill missing dates with median date\n",
    "                median_date = df_transformed[column].median()\n",
    "                df_transformed[column].fillna(median_date, inplace=True)\n",
    "                print(f\"✓ Filled {missing_count} missing values in '{column}' with median date: {median_date}\")\n",
    "            else:\n",
    "                # For categorical columns, use mode imputation\n",
    "                mode_value = df_transformed[column].mode()[0] if len(df_transformed[column].mode()) > 0 else 'Unknown'\n",
    "                df_transformed[column].fillna(mode_value, inplace=True)\n",
    "                print(f\"✓ Filled {missing_count} missing values in '{column}' with mode: '{mode_value}'\")\n",
    "else:\n",
    "    print(\"✓ No missing values found! Numeric columns were already cleaned.\")\n",
    "\n",
    "missing_after = df_transformed.isnull().sum()\n",
    "print(f\"\\nFinal missing values count: {missing_after.sum()}\")\n",
    "\n",
    "# 1.2 Check for and handle duplicates\n",
    "print(\"\\n=== DUPLICATE HANDLING ===\")\n",
    "duplicates_before = df_transformed.duplicated().sum()\n",
    "print(f\"Duplicate rows found: {duplicates_before}\")\n",
    "\n",
    "if duplicates_before > 0:\n",
    "    df_transformed.drop_duplicates(inplace=True)\n",
    "    duplicates_after = df_transformed.duplicated().sum()\n",
    "    print(f\"Duplicate rows after removal: {duplicates_after}\")\n",
    "    print(f\"Rows removed: {duplicates_before - duplicates_after}\")\n",
    "else:\n",
    "    print(\"✓ No duplicate rows found!\")\n",
    "\n",
    "print(f\"\\nDataset shape after cleaning: {df_transformed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1c600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Track Score</th>\n",
       "      <th>Spotify Streams</th>\n",
       "      <th>Spotify Playlist Count</th>\n",
       "      <th>Spotify Playlist Reach</th>\n",
       "      <th>Spotify Popularity</th>\n",
       "      <th>YouTube Views</th>\n",
       "      <th>YouTube Likes</th>\n",
       "      <th>TikTok Posts</th>\n",
       "      <th>TikTok Likes</th>\n",
       "      <th>...</th>\n",
       "      <th>Apple Music Playlist Count</th>\n",
       "      <th>AirPlay Spins</th>\n",
       "      <th>SiriusXM Spins</th>\n",
       "      <th>Deezer Playlist Count</th>\n",
       "      <th>Deezer Playlist Reach</th>\n",
       "      <th>Amazon Playlist Count</th>\n",
       "      <th>Pandora Streams</th>\n",
       "      <th>Pandora Track Stations</th>\n",
       "      <th>Soundcloud Streams</th>\n",
       "      <th>Shazam Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4598</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4598.000000</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4.598000e+03</td>\n",
       "      <td>4.598000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021-01-27 10:44:50.213136128</td>\n",
       "      <td>41.850892</td>\n",
       "      <td>4.423060e+08</td>\n",
       "      <td>58985.159417</td>\n",
       "      <td>2.319373e+07</td>\n",
       "      <td>64.110918</td>\n",
       "      <td>3.857353e+08</td>\n",
       "      <td>2.816064e+06</td>\n",
       "      <td>7.502611e+05</td>\n",
       "      <td>9.432728e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>51.366464</td>\n",
       "      <td>4.980662e+04</td>\n",
       "      <td>178.333406</td>\n",
       "      <td>28.852110</td>\n",
       "      <td>1.081997e+06</td>\n",
       "      <td>23.431057</td>\n",
       "      <td>6.814784e+07</td>\n",
       "      <td>6.583345e+04</td>\n",
       "      <td>6.427883e+06</td>\n",
       "      <td>2.319603e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1987-07-21 00:00:00</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>1.071000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.130000e+02</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019-07-17 06:00:00</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>7.315308e+07</td>\n",
       "      <td>7017.250000</td>\n",
       "      <td>4.896219e+06</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>4.576491e+07</td>\n",
       "      <td>4.486530e+05</td>\n",
       "      <td>6.742500e+04</td>\n",
       "      <td>9.398120e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.072500e+02</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.346800e+04</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.599863e+06</td>\n",
       "      <td>2.730000e+03</td>\n",
       "      <td>3.224599e+06</td>\n",
       "      <td>2.884645e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-06-01 00:00:00</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>2.398507e+08</td>\n",
       "      <td>32312.000000</td>\n",
       "      <td>1.325948e+07</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.482696e+08</td>\n",
       "      <td>1.257935e+06</td>\n",
       "      <td>1.822000e+05</td>\n",
       "      <td>2.653441e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.953000e+03</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.371200e+05</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.273577e+07</td>\n",
       "      <td>7.832000e+03</td>\n",
       "      <td>3.224599e+06</td>\n",
       "      <td>8.545840e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-11 00:00:00</td>\n",
       "      <td>44.475000</td>\n",
       "      <td>6.118920e+08</td>\n",
       "      <td>84952.750000</td>\n",
       "      <td>2.931328e+07</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>4.202808e+08</td>\n",
       "      <td>3.354939e+06</td>\n",
       "      <td>4.603338e+05</td>\n",
       "      <td>6.729765e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3.643425e+04</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.080752e+05</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.653577e+07</td>\n",
       "      <td>2.361350e+04</td>\n",
       "      <td>3.224599e+06</td>\n",
       "      <td>2.243324e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-06-14 00:00:00</td>\n",
       "      <td>725.400000</td>\n",
       "      <td>4.281469e+09</td>\n",
       "      <td>590392.000000</td>\n",
       "      <td>2.623434e+08</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.632276e+10</td>\n",
       "      <td>6.231118e+07</td>\n",
       "      <td>4.290000e+07</td>\n",
       "      <td>2.347422e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>859.000000</td>\n",
       "      <td>1.777811e+06</td>\n",
       "      <td>7098.000000</td>\n",
       "      <td>632.000000</td>\n",
       "      <td>4.819785e+07</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>1.463624e+09</td>\n",
       "      <td>3.780513e+06</td>\n",
       "      <td>3.198359e+08</td>\n",
       "      <td>2.197945e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>38.550706</td>\n",
       "      <td>5.328602e+08</td>\n",
       "      <td>70679.709393</td>\n",
       "      <td>2.948599e+07</td>\n",
       "      <td>14.766204</td>\n",
       "      <td>6.810648e+08</td>\n",
       "      <td>4.454401e+06</td>\n",
       "      <td>2.134201e+06</td>\n",
       "      <td>4.891039e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>67.678686</td>\n",
       "      <td>1.217759e+05</td>\n",
       "      <td>415.979865</td>\n",
       "      <td>49.037877</td>\n",
       "      <td>3.205493e+06</td>\n",
       "      <td>23.084704</td>\n",
       "      <td>1.496195e+08</td>\n",
       "      <td>2.249099e+05</td>\n",
       "      <td>1.764439e+07</td>\n",
       "      <td>5.675627e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Release Date  Track Score  Spotify Streams  \\\n",
       "count                           4598  4598.000000     4.598000e+03   \n",
       "mean   2021-01-27 10:44:50.213136128    41.850892     4.423060e+08   \n",
       "min              1987-07-21 00:00:00    19.400000     1.071000e+03   \n",
       "25%              2019-07-17 06:00:00    23.300000     7.315308e+07   \n",
       "50%              2022-06-01 00:00:00    29.900000     2.398507e+08   \n",
       "75%              2023-08-11 00:00:00    44.475000     6.118920e+08   \n",
       "max              2024-06-14 00:00:00   725.400000     4.281469e+09   \n",
       "std                              NaN    38.550706     5.328602e+08   \n",
       "\n",
       "       Spotify Playlist Count  Spotify Playlist Reach  Spotify Popularity  \\\n",
       "count             4598.000000            4.598000e+03         4598.000000   \n",
       "mean             58985.159417            2.319373e+07           64.110918   \n",
       "min                  1.000000            1.000000e+00            1.000000   \n",
       "25%               7017.250000            4.896219e+06           62.000000   \n",
       "50%              32312.000000            1.325948e+07           67.000000   \n",
       "75%              84952.750000            2.931328e+07           71.000000   \n",
       "max             590392.000000            2.623434e+08           96.000000   \n",
       "std              70679.709393            2.948599e+07           14.766204   \n",
       "\n",
       "       YouTube Views  YouTube Likes  TikTok Posts  TikTok Likes  ...  \\\n",
       "count   4.598000e+03   4.598000e+03  4.598000e+03  4.598000e+03  ...   \n",
       "mean    3.857353e+08   2.816064e+06  7.502611e+05  9.432728e+07  ...   \n",
       "min     9.130000e+02   2.500000e+01  1.000000e+00  3.000000e+00  ...   \n",
       "25%     4.576491e+07   4.486530e+05  6.742500e+04  9.398120e+06  ...   \n",
       "50%     1.482696e+08   1.257935e+06  1.822000e+05  2.653441e+07  ...   \n",
       "75%     4.202808e+08   3.354939e+06  4.603338e+05  6.729765e+07  ...   \n",
       "max     1.632276e+10   6.231118e+07  4.290000e+07  2.347422e+10  ...   \n",
       "std     6.810648e+08   4.454401e+06  2.134201e+06  4.891039e+08  ...   \n",
       "\n",
       "       Apple Music Playlist Count  AirPlay Spins  SiriusXM Spins  \\\n",
       "count                 4598.000000   4.598000e+03     4598.000000   \n",
       "mean                    51.366464   4.980662e+04      178.333406   \n",
       "min                      1.000000   1.000000e+00        1.000000   \n",
       "25%                     12.000000   7.072500e+02       74.000000   \n",
       "50%                     28.000000   5.953000e+03       86.000000   \n",
       "75%                     60.000000   3.643425e+04      103.000000   \n",
       "max                    859.000000   1.777811e+06     7098.000000   \n",
       "std                     67.678686   1.217759e+05      415.979865   \n",
       "\n",
       "       Deezer Playlist Count  Deezer Playlist Reach  Amazon Playlist Count  \\\n",
       "count            4598.000000           4.598000e+03            4598.000000   \n",
       "mean               28.852110           1.081997e+06              23.431057   \n",
       "min                 1.000000           1.000000e+00               1.000000   \n",
       "25%                 7.000000           8.346800e+04              10.000000   \n",
       "50%                15.000000           2.371200e+05              17.000000   \n",
       "75%                30.000000           6.080752e+05              28.000000   \n",
       "max               632.000000           4.819785e+07             210.000000   \n",
       "std                49.037877           3.205493e+06              23.084704   \n",
       "\n",
       "       Pandora Streams  Pandora Track Stations  Soundcloud Streams  \\\n",
       "count     4.598000e+03            4.598000e+03        4.598000e+03   \n",
       "mean      6.814784e+07            6.583345e+04        6.427883e+06   \n",
       "min       2.000000e+00            1.000000e+00        1.800000e+01   \n",
       "25%       2.599863e+06            2.730000e+03        3.224599e+06   \n",
       "50%       1.273577e+07            7.832000e+03        3.224599e+06   \n",
       "75%       4.653577e+07            2.361350e+04        3.224599e+06   \n",
       "max       1.463624e+09            3.780513e+06        3.198359e+08   \n",
       "std       1.496195e+08            2.249099e+05        1.764439e+07   \n",
       "\n",
       "       Shazam Counts  \n",
       "count   4.598000e+03  \n",
       "mean    2.319603e+06  \n",
       "min     1.000000e+00  \n",
       "25%     2.884645e+05  \n",
       "50%     8.545840e+05  \n",
       "75%     2.243324e+06  \n",
       "max     2.197945e+08  \n",
       "std     5.675627e+06  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55dfee",
   "metadata": {},
   "source": [
    "# Normalization/Standardization\n",
    "\n",
    "Now we need to scale our numerical features for machine learning algorithms. Different features have vastly different scales (e.g., streams vs. popularity scores), so normalization is essential.\n",
    "\n",
    "## Scaling Strategy:\n",
    "1. **StandardScaler (Z-score)**: For normally distributed features\n",
    "2. **MinMaxScaler**: For features with outliers or bounded ranges  \n",
    "3. **RobustScaler**: For features with many outliers\n",
    "\n",
    "We'll analyze each feature's distribution to choose the best scaling method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84019577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scaling libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Identify numerical columns that need scaling (exclude boolean and categorical)\n",
    "numerical_cols_for_scaling = df_transformed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove columns that shouldn't be scaled\n",
    "exclude_from_scaling = ['All Time Rank']  # Rankings should maintain their order meaning\n",
    "if 'All Time Rank' in numerical_cols_for_scaling:\n",
    "    numerical_cols_for_scaling.remove('All Time Rank')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd21843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUTION ANALYSIS & SCALER RECOMMENDATIONS ===\n",
      "\n",
      "Track Score:\n",
      "  Outliers: 8.7% | Skewness: 5.69\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (5.69))\n",
      "\n",
      "Spotify Streams:\n",
      "  Outliers: 7.0% | Skewness: 2.07\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (2.07))\n",
      "\n",
      "Spotify Playlist Count:\n",
      "  Outliers: 5.3% | Skewness: 1.86\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (1.86))\n",
      "\n",
      "Spotify Playlist Reach:\n",
      "  Outliers: 8.2% | Skewness: 2.62\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (2.62))\n",
      "\n",
      "Spotify Popularity:\n",
      "  Outliers: 9.9% | Skewness: -2.35\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (-2.35))\n",
      "\n",
      "YouTube Views:\n",
      "  Outliers: 11.0% | Skewness: 6.23\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (6.23))\n",
      "\n",
      "YouTube Likes:\n",
      "  Outliers: 8.9% | Skewness: 4.39\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (4.39))\n",
      "\n",
      "TikTok Posts:\n",
      "  Outliers: 15.3% | Skewness: 8.78\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (8.78))\n",
      "\n",
      "TikTok Likes:\n",
      "  Outliers: 13.0% | Skewness: 35.96\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (35.96))\n",
      "\n",
      "TikTok Views:\n",
      "  Outliers: 13.6% | Skewness: 34.81\n",
      "  → Recommended: MinMaxScaler (Positive values with moderate skew (34.81))\n",
      "\n",
      "=== SCALER SUMMARY ===\n",
      "MinMaxScaler: 10 columns\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze distribution and recommend scaler\n",
    "def analyze_distribution_and_recommend_scaler(series, column_name):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of a numerical column and recommend the best scaler\n",
    "    \"\"\"\n",
    "    # Calculate statistics\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calculate outlier boundaries\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
    "    outlier_percentage = len(outliers) / len(series) * 100\n",
    "    \n",
    "    # Calculate skewness (measure of asymmetry)\n",
    "    skewness = series.skew()\n",
    "    \n",
    "    # Recommend scaler based on characteristics\n",
    "    if outlier_percentage > 20:  # Many outliers\n",
    "        recommended_scaler = \"RobustScaler\"\n",
    "        reason = f\"High outlier percentage ({outlier_percentage:.1f}%)\"\n",
    "    elif abs(skewness) < 0.5:  # Relatively normal distribution\n",
    "        recommended_scaler = \"StandardScaler\"\n",
    "        reason = f\"Normal-like distribution (skew: {skewness:.2f})\"\n",
    "    elif series.min() >= 0:  # Non-negative values\n",
    "        recommended_scaler = \"MinMaxScaler\" \n",
    "        reason = f\"Positive values with moderate skew ({skewness:.2f})\"\n",
    "    else:\n",
    "        recommended_scaler = \"StandardScaler\"\n",
    "        reason = \"Default choice for mixed positive/negative values\"\n",
    "    \n",
    "    return {\n",
    "        'column': column_name,\n",
    "        'outlier_pct': outlier_percentage,\n",
    "        'skewness': skewness,\n",
    "        'recommended_scaler': recommended_scaler,\n",
    "        'reason': reason\n",
    "    }\n",
    "\n",
    "# Analyze all numerical columns\n",
    "print(\"=== DISTRIBUTION ANALYSIS & SCALER RECOMMENDATIONS ===\")\n",
    "scaler_recommendations = {}\n",
    "\n",
    "for col in numerical_cols_for_scaling[:10]:  # Analyze first 10 columns to avoid too much output\n",
    "    analysis = analyze_distribution_and_recommend_scaler(df_transformed[col], col)\n",
    "    scaler_recommendations[col] = analysis['recommended_scaler']\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Outliers: {analysis['outlier_pct']:.1f}% | Skewness: {analysis['skewness']:.2f}\")\n",
    "    print(f\"  → Recommended: {analysis['recommended_scaler']} ({analysis['reason']})\")\n",
    "\n",
    "print(f\"\\n=== SCALER SUMMARY ===\")\n",
    "scaler_counts = {}\n",
    "for scaler in scaler_recommendations.values():\n",
    "    scaler_counts[scaler] = scaler_counts.get(scaler, 0) + 1\n",
    "\n",
    "for scaler, count in scaler_counts.items():\n",
    "    print(f\"{scaler}: {count} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPLYING SCALING ===\n"
     ]
    }
   ],
   "source": [
    "# Apply scaling based on recommendations\n",
    "print(\"=== SCALING ===\")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Create column name mapping for scaled features\n",
    "scaled_columns = [f\"{col}\" for col in numerical_cols_for_scaling]\n",
    "\n",
    "# Apply scaling\n",
    "scaled_data = scaler.fit_transform(df_transformed[numerical_cols_for_scaling])\n",
    "\n",
    "# Create DataFrame with scaled features\n",
    "df_scaled_features = pd.DataFrame(\n",
    "    scaled_data, \n",
    "    columns=scaled_columns,\n",
    "    index=df_transformed.index\n",
    ")\n",
    "\n",
    "# Combine scaled numerical features with non-numerical features\n",
    "non_numerical_cols = [col for col in df_transformed.columns if col not in numerical_cols_for_scaling]\n",
    "df_final_scaled = pd.concat([\n",
    "    df_transformed[non_numerical_cols],  # Keep original non-numerical columns\n",
    "    df_scaled_features             # Add scaled numerical columns\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df438ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of                                 Track                        Album Name  \\\n",
      "0                 MILLION DOLLAR BABY      Million Dollar Baby - Single   \n",
      "1                         Not Like Us                       Not Like Us   \n",
      "2          i like the way you kiss me        I like the way you kiss me   \n",
      "3                             Flowers                  Flowers - Single   \n",
      "4                             Houdini                           Houdini   \n",
      "...                               ...                               ...   \n",
      "4595                For the Last Time                 For the Last Time   \n",
      "4596                 Dil Meri Na Sune  Dil Meri Na Sune (From \"Genius\")   \n",
      "4597            Grace (feat. 42 Dugg)                           My Turn   \n",
      "4598              Nashe Si Chadh Gayi             November Top 10 Songs   \n",
      "4599  Me Acostumbre (feat. Bad Bunny)   Me Acostumbre (feat. Bad Bunny)   \n",
      "\n",
      "              Artist Release Date          ISRC All Time Rank  Explicit Track  \\\n",
      "0      Tommy Richman   2024-04-26  QM24S2402528             1           False   \n",
      "1     Kendrick Lamar   2024-05-04  USUG12400910             2            True   \n",
      "2            Artemas   2024-03-19  QZJ842400387             3           False   \n",
      "3        Miley Cyrus   2023-01-12  USSM12209777             4           False   \n",
      "4             Eminem   2024-05-31  USUG12403398             5            True   \n",
      "...              ...          ...           ...           ...             ...   \n",
      "4595     $uicideboy$   2017-09-05  QM8DG1703420         4,585            True   \n",
      "4596      Atif Aslam   2018-07-27  INT101800122         4,575           False   \n",
      "4597        Lil Baby   2020-02-28  USUG12000043         4,571            True   \n",
      "4598    Arijit Singh   2016-11-08  INY091600067         4,591           False   \n",
      "4599       Arcï¿½ï¿½   2017-04-11  USB271700107         4,593            True   \n",
      "\n",
      "      Track Score  Spotify Streams  Spotify Playlist Count  ...  \\\n",
      "0       32.845336         0.279579               -0.020478  ...   \n",
      "1       24.368359         0.155647               -0.053878  ...   \n",
      "2       24.014168         0.670935                0.282529  ...   \n",
      "3       19.598583         3.325228                3.047263  ...   \n",
      "4       18.578512        -0.246531               -0.321920  ...   \n",
      "...           ...              ...                     ...  ...   \n",
      "4595    -0.495868         0.121022                0.429304  ...   \n",
      "4596    -0.495868        -0.348162               -0.355550  ...   \n",
      "4597    -0.495868        -0.092583                0.510088  ...   \n",
      "4598    -0.495868        -0.175194               -0.234489  ...   \n",
      "4599    -0.495868         0.029495               -0.002233  ...   \n",
      "\n",
      "      Apple Music Playlist Count  AirPlay Spins  SiriusXM Spins  \\\n",
      "0                       3.791667       0.980267       20.620690   \n",
      "1                       3.333333       0.974753       -2.862069   \n",
      "2                       3.375000       1.913959       15.517241   \n",
      "3                       7.625000      41.113052       72.275862   \n",
      "4                       3.208333       0.174434       -2.931034   \n",
      "...                          ...            ...             ...   \n",
      "4595                   -0.520833      -0.166457        0.000000   \n",
      "4596                   -0.562500      -0.155093        0.000000   \n",
      "4597                   -0.187500      -0.160915        0.000000   \n",
      "4598                   -0.562500      -0.133037        0.000000   \n",
      "4599                   -0.354167      -0.108321        0.000000   \n",
      "\n",
      "      Deezer Playlist Count  Deezer Playlist Reach  Amazon Playlist Count  \\\n",
      "0                  2.043478              33.094468               5.388889   \n",
      "1                  2.260870              19.415115               5.222222   \n",
      "2                  5.260870              68.784271               8.611111   \n",
      "3                 10.826087              46.600820              10.722222   \n",
      "4                  2.913043              33.212473               4.888889   \n",
      "...                     ...                    ...                    ...   \n",
      "4595              -0.565217              -0.424895               0.000000   \n",
      "4596              -0.608696              -0.450228               0.000000   \n",
      "4597              -0.608696              -0.451854              -0.611111   \n",
      "4598               0.000000               0.000000              -0.555556   \n",
      "4599              -0.478261              -0.208996              -0.722222   \n",
      "\n",
      "      Pandora Streams  Pandora Track Stations  Soundcloud Streams  \\\n",
      "0            0.119922                0.723011           1593858.0   \n",
      "1           -0.112795                0.986999           3398476.0   \n",
      "2           -0.175555               -0.105011           3984052.0   \n",
      "3            4.040534                9.363948                 0.0   \n",
      "4           -0.187589               -0.039553          -3017420.0   \n",
      "...               ...                     ...                 ...   \n",
      "4595         0.167706                0.256279          47408407.0   \n",
      "4596         0.000000                0.000000                 0.0   \n",
      "4597         1.631717                1.013575                 0.0   \n",
      "4598        -0.134695                0.000000                 0.0   \n",
      "4599         1.280751                0.167022                 0.0   \n",
      "\n",
      "      Shazam Counts  \n",
      "0          0.928291  \n",
      "1          0.134892  \n",
      "2          2.266535  \n",
      "3          5.610818  \n",
      "4         -0.203374  \n",
      "...             ...  \n",
      "4595      -0.101412  \n",
      "4596      -0.338129  \n",
      "4597       0.143956  \n",
      "4598      -0.207837  \n",
      "4599      -0.044800  \n",
      "\n",
      "[4598 rows x 28 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_final_scaled.describe)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc699822",
   "metadata": {},
   "source": [
    "# Export to CSV\n",
    "\n",
    "Now that our data is clean and transformed, let's export it to CSV format for further analysis or use in other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75b8b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "output_filename = f\"music_data_cleaned.csv\"\n",
    "output_path = f\"./{output_filename}\"\n",
    "\n",
    "\n",
    "df_final_scaled.to_csv(f\"./{output_path}\", index=False)\n",
    "\n",
    "\n",
    "# Export to CSV\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    df_transformed.to_csv(output_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec512e",
   "metadata": {},
   "source": [
    "# Modelling & Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c30cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Track', 'Album Name', 'Artist', 'Release Date', 'ISRC', 'All Time Rank', 'Explicit Track', 'Track Score', 'Spotify Streams', 'Spotify Playlist Count', 'Spotify Playlist Reach', 'Spotify Popularity', 'YouTube Views', 'YouTube Likes', 'TikTok Posts', 'TikTok Likes', 'TikTok Views', 'YouTube Playlist Reach', 'Apple Music Playlist Count', 'AirPlay Spins', 'SiriusXM Spins', 'Deezer Playlist Count', 'Deezer Playlist Reach', 'Amazon Playlist Count', 'Pandora Streams', 'Pandora Track Stations', 'Soundcloud Streams', 'Shazam Counts']\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Cargar CSV\n",
    "CSV_PATH = Path(\"music_data_cleaned.csv\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fe30e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Modelo       MAE       MSE      RMSE        R²\n",
      "3            XGBoost  0.231018  0.236269  0.486075  0.769190\n",
      "2      Random Forest  0.223302  0.238728  0.488598  0.766787\n",
      "1   Lasso Regression  0.294386  0.329095  0.573668  0.678508\n",
      "0  Linear Regression  0.294605  0.329767  0.574254  0.677851\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2) Definir target y features\n",
    "target_col = \"Spotify Streams\"   # ajusta si tu columna objetivo se llama diferente\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# solo numéricas\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# --- 3) Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- 4) Definir modelos\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.001, max_iter=10000, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    models[\"XGBoost\"] = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "except ImportError:\n",
    "    models[\"Gradient Boosting\"] = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# --- 5) Entrenar y evaluar\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "\n",
    "    results.append([name, mae, mse, rmse, r2])\n",
    "\n",
    "# --- 6) Tabla de resultados\n",
    "results_df = pd.DataFrame(results, columns=[\"Modelo\", \"MAE\", \"MSE\", \"RMSE\", \"R²\"])\n",
    "print(results_df.sort_values(by=\"R²\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
